for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
x <- rlnorm(5)
y <- rlnorm(5, meanlog=0.5)
pool <- c(x, y)
null.dist <- numeric(10000)
for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
x <- rlnorm(10)
y <- rlnorm(10, meanlog=0.5)
pool <- c(x, y)
null.dist <- numeric(10000)
for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
t.test(x, y)
t.test(x, y, var.equal=T)
t.test.res <- t.test(x, y)
mean(abs(null.dist) >= abs(t.test.res$statistic))
t.test(x, y, var.equal=T)
mean(abs(null.dist) >= abs(t.test.res$statistic))
sum(abs(null.dist) >= abs(t.test.res$statistic))/length(null.dist)
x <- rlnorm(50)
y <- rlnorm(50, meanlog=0.5)
pool <- c(x, y)
null.dist <- numeric(10000)
for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
t.test.res <- t.test(x, y)
mean(abs(null.dist) >= abs(t.test.res$statistic))
t.test(x,y)
t.test(x,y, var.equal=T)
x <- rlnorm(100)
y <- rlnorm(100, meanlog=0.5)
pool <- c(x, y)
null.dist <- numeric(10000)
for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
t.test.res <- t.test(x, y)
mean(abs(null.dist) >= abs(t.test.res$statistic))
t.test(x,y)
t.test(x,y, var.equal=T
)
x <- rlnorm(500)
y <- rlnorm(500, meanlog=0.5)
pool <- c(x, y)
null.dist <- numeric(10000)
for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
t.test.res <- t.test(x, y)
mean(abs(null.dist) >= abs(t.test.res$statistic))
t.test(x,y)
1/10000
x <- rlnorm(100)
y <- rlnorm(100, meanlog=0.5)
pool <- c(x, y)
null.dist <- numeric(10000)
for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
t.test.res <- t.test(x, y)
mean(abs(null.dist) >= abs(t.test.res$statistic))
t.test(x,y)
t.test(x,y, var.equal=T)
x <- rlnorm(10)
y <- rlnorm(10, meanlog=0.5)
pool <- c(x, y)
null.dist <- numeric(10000)
for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
t.test.res <- t.test(x, y)
mean(abs(null.dist) >= abs(t.test.res$statistic))
t.test(x,y)
t.test(x,y, var.equal=T)
x <- rlnorm(20)
y <- rlnorm(20, meanlog=0.5)
pool <- c(x, y)
null.dist <- numeric(10000)
for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
t.test.res <- t.test(x, y)
mean(abs(null.dist) >= abs(t.test.res$statistic))
t.test(x,y)
t.test(x,y, var.equal=T)
x <- rlnorm(20)
y <- rlnorm(20, meanlog=0.5)
pool <- c(x, y)
null.dist <- numeric(10000)
for(i in seq_along(null.dist)){
x1 <- sample(pool, size = length(x), replace = TRUE)
y1 <- sample(pool, size = length(y), replace = TRUE)
null.dist[i] <- t.test(x1, y1, var.equal = TRUE)$statistic
}
hist(null.dist, freq = FALSE, ylim = c(0, 0.5))
x.plot <- seq(-5, 5, length.out = 1000)
lines(x.plot, dt(x.plot, df = length(x) + length(y) - 2), lwd = 2)
t.test.res <- t.test(x, y)
mean(abs(null.dist) >= abs(t.test.res$statistic))
t.test(x,y)
t.test(x,y, var.equal=T)
wilcox.test(x,y)
p <- 0.01
n <- seq(1, 10000)
lambda <- n * p
geom
geom <- (1 - p) ^ n
expon <- exp(-lambda)
plot(n, geom-expon)
abline(h=0, col="red")
plot(n, geom-expon, type = "l")
abline(h = 0, col = "red")
windows()
p <- 0.001
n <- seq(1, 10000)
lambda <- n * p
geom <- (1 - p) ^ n
expon <- exp(-lambda)
plot(n, geom-expon, type = "l")
abline(h = 0, col = "red")
p <- 0.0001
n <- seq(1, 10000)
lambda <- n * p
geom <- (1 - p) ^ n
expon <- exp(-lambda)
plot(n, geom-expon, type = "l")
abline(h = 0, col = "red")
p <- 0.0001
n <- seq(1, 100000)
lambda <- n * p
geom <- (1 - p) ^ n
expon <- exp(-lambda)
plot(n, geom-expon, type = "l")
abline(h = 0, col = "red")
p <- 0.0001
n <- seq(1, 100000)
lambda <- n * p
geom <- (1 - p) ^ n
expon <- exp(-lambda)
plot(n, geom-expon, type = "l", log = "x")
abline(h = 0, col = "red")
1 - p
exp(-1 * p)
p <- 0.01
hor <- rbinom(100, 1, p)
hor
sum(hor)
hor <- rbinom(1000, 1, p)
sum(hor)
hor
FAD <- which(hor == 1)[1]
which(hor == 1)
LAD <- max(which(hor == 1))
LAD
Range <- LAD - FAD
Range
n <- sum(hor)
Range * (1 - 0.95) ^ (-1 / (n - 1)) - 1
SS89 <- Range * (1 - 0.95) ^ (-1 / (n - 1)) - 1
Range <- LAD - FAD + 1
n <- sum(hor)
SS89 <- Range * (1 - 0.95) ^ (-1 / (n - 1)) - 1
SS89
Range
p_hat <- hor / Range
log(0.95) / log(1 - p_hat)
log(0.95)
log(1 - p_hat)
hor
p_hat <- n / Range
log(0.95) / log(1 - p_hat)
log(0.05) / log(1 - p_hat)
log(0.95) / log(1 - p_hat)
Range * (1 - 0.95) ^ (-1 / (n - 1)) - 1
(1 - 0.95) ^ (-1 / (n - 1)) - 1
SS89 <- Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
SS89
log(0.95) / log(1 - p_hat)
p <- 0.0001
hor <- rbinom(1000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
SS89 <- Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.95) / log(1 - p_hat)
SS89
p <- 0.001
hor <- rbinom(1000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
SS89 <- Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.95) / log(1 - p_hat)
SS89
p <- 0.0001
hor <- rbinom(100000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.95) / log(1 - p_hat)
p <- 0.5
hor <- rbinom(100000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.95) / log(1 - p_hat)
p <- 0.1
hor <- rbinom(100000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.95) / log(1 - p_hat)
p <- 0.1
hor <- rbinom(10000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.95) / log(1 - p_hat)
p <- 0.01
hor <- rbinom(10000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.95) / log(1 - p_hat)
p_hat
1 - (1 - p_hat) ^ 100
1 - (1 - p_hat) ^ 1000
1 - (1 - p_hat) ^ 100
1 - (1 - p_hat) ^ 500
1 - (1 - p_hat) ^ 400
1 - (1 - p_hat) ^ 300
1 - (1 - p_hat) ^ 350
1 - (1 - p_hat) ^ 340
1 - (1 - p_hat) ^ 330
log(0.05) / log(1 - p_hat)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p <- 0.01
hor <- rbinom(100000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.05) / log(1 - p_hat)
p <- 0.001
hor <- rbinom(100000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.05) / log(1 - p_hat)
p <- 0.01
hor <- rbinom(1000000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.05) / log(1 - p_hat)
p <- 0.01
hor <- rbinom(10000000, 1, p)
FAD <- which(hor == 1)[1]
LAD <- max(which(hor == 1))
Range <- LAD - FAD + 1
n <- sum(hor)
Range * ((1 - 0.95) ^ (-1 / (n - 1)) - 1)
p_hat <- n / Range
log(0.05) / log(1 - p_hat)
?pgeom
choose(10,0)
500/40
library(TSA)
install.packages("TSA", dep=T)
win.graph(width=4.875, height=2.5,pointsize=8)
plot(1:10)
d <- read.delim(file.choose())
d
head(d)
dim(d)
plot(d, type="l")
plot(seq_along(d), d, type="l")
d
head(d)
class(d)
dim(d)
d=as.numeric(d)
plot(d$larain)
plot(d$larain, type="o")
prior1 <- prior2 <- 0.5
mean1 <- c(0, 0)
mean1 <- t(c(0, 0))
mean1
c(0,0)
mean1 <- matrix(c(0, 0), ncol = 1)
mean1
covar
covar <- matrix(c(1, 0, 0, 0.5625), nrow = 2)
covar
log(prior1 / prior2)
t(mean1 + mean2)
mean1 <- matrix(c(0, 0), ncol = 1)
mean2 <- matrix(c(2, -2), ncol = 1)
mean1 + mean2
t(mean1 + mean2)
covar
solve?
?solve
solve(covar)
a0 <- log(prior1 / prior2) - 0.5 * t(mean1 + mean2) %*% solve(covar) * (mean1 - mean2)
t(mean1 + mean2)
(mean1 - mean2)
t(mean1 + mean2) %*% solve(covar)
t(mean1 + mean2) %*% solve(covar) * (mean1 - mean2)
t(mean1 + mean2) %*% solve(covar) %*% (mean1 - mean2)
a0 <- log(prior1 / prior2) - 0.5 * t(mean1 + mean2) %*% solve(covar) %*% (mean1 - mean2)
a0
solve(covar) %*% (mean1 - mean2)
a[1]
a
a <- solve(covar) %*% (mean1 - mean2)
a
a[1, ]
5.56-2-3.56
d <- read.csv(file.choose(), header = TRUE)
head(d)
hist(d$Ssk)
windows()
unique(d$BSM.Type)
BSM.uniq <- sort(unique(d$BSM.Type))
BSM.uniq
for(i in seq_along(BSM.uniq)) hist(d$Ssk[d$BSM.Type == BSM.uniq[i]])
par(mfrow = c(2,2))
for(i in seq_along(BSM.uniq)) hist(d$Ssk[d$BSM.Type == BSM.uniq[i]])
head(d)
for(i in seq_along(BSM.uniq)) hist(d$Sku[d$BSM.Type == BSM.uniq[i]])
for(i in seq_along(BSM.uniq)) hist(log(d$Sku[d$BSM.Type == BSM.uniq[i]]))
BSM.uniq
colnames(d)
d1 <- d[d$BSM.Type == "Percussion" | d$BSM.Type == "Cutmark", c("Ssk", "Sku")]
head(d1)
d1 <- d[d$BSM.Type == "Percussion" | d$BSM.Type == "Cutmark", c("BSM.Type", "Ssk", "Sku")]
head(d1)
d1 <- d[d$BSM.Type == "Percussion" | d$BSM.Type == "Cutmark", c("Ssk", "Sku")]
head(d1)
d1 <- d[d$BSM.Type == "Percussion" | d$BSM.Type == "Cutmark", c("BSM.Type", "Ssk", "Sku")]
head(d1)
table(d1$BSM.Type)
prior_cut <- prior_perc <- 0.5
?lda
1.5^2
set.seed(12345); X=rnorm(105); Y=zlag(X,2)+.5*rnorm(105)
X=ts(X[-(1:5)],start=1,freq=1); Y=ts(Y[-(1:5)],start=1,freq=1)
ccf(X,Y,ylab='CCF')
install.packages("TSA", dep=T)
library(TSA)
set.seed(12345); X=rnorm(105); Y=zlag(X,2)+.5*rnorm(105)
X=ts(X[-(1:5)],start=1,freq=1); Y=ts(Y[-(1:5)],start=1,freq=1)
ccf(X,Y,ylab='CCF')
test=ccf(X,Y,ylab='CCF')
test
sqrt(4*81)
phi=seq(0,.95,.15)
rejection=2*(1-pnorm(1.96*sqrt((1-phi^2)/(1+phi^2))))
M=signif(rbind(phi,rejection),2)
rownames(M)=c('phi', 'Error Rate')
M
getwd()
setwd("C:/Users/adu/OneDrive - Colostate/Desktop/Manuscripts/Other authors/Cohen et al_climate variability/GitHub")
## Read in CMR results
CMR.res <- readRDS("CMR files/CMR results.rds")
turk_CMR.res <- readRDS("CMR files/Turkana CMR results.rds") # Turkana only
## Read in climate variability data
clim.var <- read.csv(file = "original datasets/climate variability 250ka bins.csv", header = TRUE, row.names = 1)
head(clim.var)
## remove time bins from climate variability that aren't in CMR results
clim.var1 <- clim.var[seq(1, which(rownames(clim.var) == "3625")), ]
clim.var1 <- clim.var1[, -ncol(clim.var1)]
d13C <- clim.var$Turkana_psol_d13C # Turkana psol data only
d13C <- d13C[rownames(clim.var) %in% seq(1125, 4125, 250)] # get out data synchronous with mammal data
# get out origination and extinction estimates for lumped cf treatment
cmr_cf.lump <- CMR.res$neo_cf.lump # all localities cf lumped
cf.lump_orig <- rev(1 - cmr_cf.lump$estimate[grep("Gamma", rownames(cmr_cf.lump))]) # all localities origination
cf.lump_extinct <- rev(1 - cmr_cf.lump$estimate[grep("Phi", rownames(cmr_cf.lump))]) # all localities extinction
turk_cmr_lump <- turk_CMR.res$neo_cf.lump # turkana cf lumped
turk_lump_orig <- rev(1 - turk_cmr_lump$estimate[grep("Gamma", rownames(turk_cmr_lump))]) # turkana origination
turk_lump_extinct <- rev(1 - turk_cmr_lump$estimate[grep("Phi", rownames(turk_cmr_lump))]) # turkana extinction
head(clim.var)
acf(clim.var$insolation_equator)
install.packages("tseries", dep=T)
par(mfrow = c(3,2), pty = "s") #  graphing for Figure 3a.
for (i in 1:3) {
X <- arima.sim(n = 100, list(ar = c(0.9)),sd = 1) #  simulating
#  the time series
Y <- arima.sim(n = 100, list(ar = c(0.9)),sd = 1.0)
criterion <- 1.96*sqrt((1+0.81)/(100*(1-0.81))) # Estimating the
#  correct value for p=.05 significances. See text.
ccf(X,Y, ylab= "CCF", ylim = c(-0.65, 0.65), main = paste("Cross-correlation of x and y Run", i) )
abline(h= c(criterion, -criterion))
pre-whiten(X,Y, ylim = c(-0.65, 0.65), main = paste("CCF after Pre-whitening Run", i))
}
windows()
par(mfrow = c(3,2), pty = "s") #  graphing for Figure 3a.
for (i in 1:3) {
X <- arima.sim(n = 100, list(ar = c(0.9)),sd = 1) #  simulating
#  the time series
Y <- arima.sim(n = 100, list(ar = c(0.9)),sd = 1.0)
criterion <- 1.96*sqrt((1+0.81)/(100*(1-0.81))) # Estimating the
#  correct value for p=.05 significances. See text.
ccf(X,Y, ylab= "CCF", ylim = c(-0.65, 0.65), main = paste("Cross-correlation of x and y Run", i) )
abline(h= c(criterion, -criterion))
pre-whiten(X,Y, ylim = c(-0.65, 0.65), main = paste("CCF after Pre-whitening Run", i))
}
dev.off()
windows()
par(mfrow = c(3,2), pty = "s") #  graphing for Figure 3a.
for (i in 1:3) {
X <- arima.sim(n = 100, list(ar = c(0.9)),sd = 1) #  simulating
#  the time series
Y <- arima.sim(n = 100, list(ar = c(0.9)),sd = 1.0)
criterion <- 1.96*sqrt((1+0.81)/(100*(1-0.81))) # Estimating the
#  correct value for p=.05 significances. See text.
ccf(X,Y, ylab= "CCF", ylim = c(-0.65, 0.65), main = paste("Cross-correlation of x and y Run", i) )
abline(h= c(criterion, -criterion))
pre-whiten(X,Y, ylim = c(-0.65, 0.65), main = paste("CCF after Pre-whitening Run", i))
}
par(mar = c(0, 0, 0, 0))
windows()
par(mfrow = c(3,2), pty = "s") #  graphing for Figure 3a.
for (i in 1:3) {
X <- arima.sim(n = 100, list(ar = c(0.9)),sd = 1) #  simulating
#  the time series
Y <- arima.sim(n = 100, list(ar = c(0.9)),sd = 1.0)
criterion <- 1.96*sqrt((1+0.81)/(100*(1-0.81))) # Estimating the
#  correct value for p=.05 significances. See text.
ccf(X,Y, ylab= "CCF", ylim = c(-0.65, 0.65), main = paste("Cross-correlation of x and y Run", i) )
abline(h= c(criterion, -criterion))
pre-whiten(X,Y, ylim = c(-0.65, 0.65), main = paste("CCF after Pre-whitening Run", i))
}
